{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007b5205",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52dd00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import json, os, io\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, \\\n",
    "roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.layers import Embedding, MaxPool1D\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.initializers import glorot_uniform, RandomUniform, lecun_uniform, Constant\n",
    "from collections import OrderedDict\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, GlobalMaxPool1D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool1D\n",
    "from keras_preprocessing.text import tokenizer_from_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f55447",
   "metadata": {},
   "source": [
    "Specify a constant seeder for processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbb1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219c4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropEmpty(tokens0):\n",
    "    tokens = []\n",
    "    for i in range(0, len(tokens0)):\n",
    "        temp = tokens0[i]\n",
    "        if temp != []:\n",
    "            tokens.append(temp)\n",
    "    return tokens\n",
    "\n",
    "def listToString(s): \n",
    "    \n",
    "    # initialize an empty string\n",
    "    str1 = \"\" \n",
    "    \n",
    "    # traverse in the string \n",
    "    count = 0\n",
    "    for ele in s: \n",
    "        if count==0:\n",
    "            str1 = str1 + ele\n",
    "        else:\n",
    "            str1 = str1 + ' ' + ele\n",
    "        count = count + 1\n",
    "        #str1 += ele  \n",
    "    \n",
    "    # return string  \n",
    "    return str1\n",
    "\n",
    "def prepareData(data):\n",
    "        \n",
    "    # lowercase\n",
    "    lines = []\n",
    "    labels = []\n",
    "    headlines = []\n",
    "    for i in range(0, len(data)):\n",
    "        labels.append(int(data[i][1]))\n",
    "        headlines.append(data[i][0])\n",
    "        line = data[i][2:]\n",
    "        lows = [w.lower() for w in line]\n",
    "        lines.append(lows)\n",
    "    \n",
    "    texts = []\n",
    "    for i in range(0, len(lines)):\n",
    "        texts.append(listToString(lines[i]))\n",
    "    \n",
    "    return texts, labels, headlines "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88221c5a",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6af2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join('..', '..')\n",
    "with open(os.path.join(root_path, 'data', 'dataset.csv'), newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "data = dropEmpty(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff99988",
   "metadata": {},
   "source": [
    "Shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06f1a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf95bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels, headlines = prepareData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e09f413",
   "metadata": {},
   "source": [
    "Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479d07b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements in dataset: 4184\n",
      "2 categories found:\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_elements=len(headlines)\n",
    "print('Elements in dataset:', n_elements)\n",
    "categories=sorted(list(set(labels))) #set will return the unique different entries\n",
    "n_categories=len(categories)\n",
    "print(\"{} categories found:\".format(n_categories))\n",
    "for category in categories:\n",
    "    print(category)\n",
    "    \n",
    "fig=plt.figure(figsize=(20,8))\n",
    "lbl, counts = np.unique(labels,return_counts=True)\n",
    "ticks = range(len(counts))\n",
    "plt.bar(ticks,counts, align='center')\n",
    "plt.xticks(ticks,lbl)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab7af89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class callbackmodule calls strid$ def __init__...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this_file os path abspath __file__ decode sys ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class migration migrations migration dependenc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset pd strid$ x dataset iloc numid$ values...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__metaclass__ type ansible_metadata strid$ str...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Labels\n",
       "0  class callbackmodule calls strid$ def __init__...       0\n",
       "1  this_file os path abspath __file__ decode sys ...       0\n",
       "2  class migration migrations migration dependenc...       0\n",
       "3  dataset pd strid$ x dataset iloc numid$ values...       1\n",
       "4  __metaclass__ type ansible_metadata strid$ str...       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(({'Text': texts, 'Labels': labels}))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679c62db-d0bb-4eb0-9fc0-5e64bbbbe4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of words per sequence: 510\n"
     ]
    }
   ],
   "source": [
    "word_counts = data[\"Text\"].apply(lambda x: len(x.split()))\n",
    "max_length = word_counts.max()\n",
    "print(\"Maximum number of words per sequence:\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c05ac3-b2ab-4e4d-bb13-975f69d26f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Frequencies:\n",
      " Labels\n",
      "0    3186\n",
      "1     998\n",
      "Name: count, dtype: int64\n",
      "Total samples  4184\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = data['Labels'].value_counts()\n",
    "print(\"Label Frequencies:\\n\", label_frequencies)\n",
    "print(\"Total samples \", len(data))\n",
    "n_categories = len(label_frequencies)\n",
    "print(\"Number of classes:\", n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c17e94d-d33a-4580-82f5-82694cdf418f",
   "metadata": {},
   "source": [
    "Create word embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ba78a0-056d-4cb8-9579-ccdc9cd07b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringToList(string):\n",
    "    codeLinesList = []\n",
    "    for line in string.split():\n",
    "        codeLinesList.append(line)\n",
    "    return codeLinesList\n",
    "\n",
    "allTokens = []\n",
    "for seq in data[\"Text\"]:\n",
    "    listSeq = stringToList(seq)\n",
    "    allTokens.append(listSeq)\n",
    "\n",
    "data[\"Tokens\"] = allTokens\n",
    "#data[\"Tokens\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8bde0a7-992d-4c62-a05b-7cf3894d782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embedding \n",
    "embeddings_index = {}\n",
    "f = open('w2v_embeddings.txt', encoding=\"utf-8\")\n",
    "for line in f:    \n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs   \n",
    "f.close() \n",
    "\n",
    "dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788c002f-2ba3-42da-831d-bfe27fbd53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_obj = Tokenizer()   \n",
    "tokenizer_obj.fit_on_texts(data[\"Tokens\"])\n",
    "\n",
    "tokenizer_json = tokenizer_obj.to_json()\n",
    "tokenizerFile = 'w2v_tokenizer.json'\n",
    "\n",
    "with io.open(tokenizerFile, 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "\n",
    "with open(tokenizerFile) as f:\n",
    "    dataTokenizer = json.load(f)\n",
    "    tokenizer_obj = tokenizer_from_json(dataTokenizer)\n",
    "\n",
    "sequences = tokenizer_obj.texts_to_sequences(data[\"Tokens\"])\n",
    "word_index = tokenizer_obj.word_index\n",
    "\n",
    "lines_pad = pad_sequences(sequences, padding = 'post', maxlen = max_length)\n",
    "\n",
    "num_words = len(word_index) + 1 # +1 for the unknown-zeros\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, dim))\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    #embedding_vector = embeddings_index.get(word)\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b6f1bb",
   "metadata": {},
   "source": [
    "Split to train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f3b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b54033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_x, test_x, train_val_y, test_y = train_test_split(lines_pad, data['Labels'], test_size=val_ratio, random_state=seed, stratify=data['Labels'])\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_val_x, train_val_y, test_size=val_ratio, random_state=seed, stratify=train_val_y)\n",
    "# print(len(data))\n",
    "# print(len(train_val_data))\n",
    "# print(len(test_data))\n",
    "# print(len(train_data))\n",
    "# print(len(val_data))\n",
    "# print(len(val_data)+len(train_data)+len(test_data))\n",
    "# print(len(val_data)+len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c93ea56e-8a53-40f7-96c5-96ef1421cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "x_train = train_x\n",
    "x_val = val_x\n",
    "x_test = test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1877644",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_y)\n",
    "y_val = np.array(val_y)\n",
    "y_test = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc7a662-c72d-4107-8858-a2294da5fb8d",
   "metadata": {},
   "source": [
    "Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1613b2a-b8d3-44d5-af45-eced7f1a5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions\n",
    "def recall_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f1 = 2*((prec*rec)/(prec+rec+K.epsilon()))\n",
    "    return f1\n",
    "\n",
    "def f2_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f2 = 5*((prec*rec)/(4*prec+rec+K.epsilon()))\n",
    "    return f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912029eb-5506-4dd3-b5d8-04d70baf6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildCnn(max_len, top_words, dim, seed, embedding_matrix, multi, n_outputs):\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Embedding(top_words, dim, input_length=None, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "    cnn_model.add(Conv1D(filters = 128, kernel_size = 1, activation = 'relu'))\n",
    "    '''cnn_model.add(MaxPooling1D(pool_size = 5))\n",
    "    cnn_model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size = 5))\n",
    "    cnn_model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu'))'''\n",
    "    cnn_model.add(GlobalMaxPool1D())\n",
    "    #cnn_model.add(Dense(units = 128, activation = 'relu'))\n",
    "    if multi == False:\n",
    "        cnn_model.add(Dense(n_outputs, activation = 'sigmoid'))\n",
    "        cnn_model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics=[f1_metric])\n",
    "    else: \n",
    "        model.add(Dense(n_outputs, activation='softmax'))\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return cnn_model\n",
    "\n",
    "    \n",
    "def buildLstm(max_len, top_words, dim, optimizer, seed, embedding_matrix, multi, n_outputs):\n",
    "    model=Sequential()\n",
    "    #model.add(Embedding(input_dim=top_words+1, output_dim=dim, input_length=None, mask_zero=True))\n",
    "    model.add(Embedding(input_dim=top_words, output_dim=dim, input_length=None, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "    #model.add(SimpleRNN(300, dropout=0.3, stateful=False))\n",
    "    model.add(LSTM(100, dropout=0.2, return_sequences=True, stateful=False))\n",
    "    model.add(LSTM(50, dropout=0.1, stateful=False))\n",
    "    #model.add(Bidirectional(LSTM(300, dropout=0.3, stateful=False)))\n",
    "    #model.add(GRU(300, dropout=0.3, stateful=False))\n",
    "    model.add(Activation('relu')) #dropout=0.2, recurrent_dropout=0.2, kernel_constraint=max_norm(3), bias_constraint=max_norm(3)\n",
    "    model.add(BatchNormalization())\n",
    "    if multi == False:\n",
    "        model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[f1_metric])  \n",
    "    else: \n",
    "        model.add(Dense(n_outputs, activation='softmax'))\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "425ddd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "userModel = \"lstm\"\n",
    "\n",
    "# hyperparams\n",
    "n_epoch = 100\n",
    "batch_size = 128\n",
    "optimizer = 'adam'\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1836761",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5da66cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 200)         2136600   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 100)         120400    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                30200     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 50)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 50)               200       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,287,451\n",
      "Trainable params: 150,751\n",
      "Non-trainable params: 2,136,700\n",
      "_________________________________________________________________\n",
      "model summary\\m None\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6357 - f1_metric: 0.4810\n",
      "Epoch 1: val_f1_metric improved from -inf to 0.44534, saving model to best_model.h5\n",
      "27/27 [==============================] - 59s 2s/step - loss: 0.6357 - f1_metric: 0.4810 - val_loss: 0.6382 - val_f1_metric: 0.4453\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5084 - f1_metric: 0.5896\n",
      "Epoch 2: val_f1_metric did not improve from 0.44534\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.5084 - f1_metric: 0.5896 - val_loss: 0.5738 - val_f1_metric: 0.1272\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4202 - f1_metric: 0.6444\n",
      "Epoch 3: val_f1_metric did not improve from 0.44534\n",
      "27/27 [==============================] - 46s 2s/step - loss: 0.4202 - f1_metric: 0.6444 - val_loss: 0.5248 - val_f1_metric: 0.2881\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3539 - f1_metric: 0.7092\n",
      "Epoch 4: val_f1_metric did not improve from 0.44534\n",
      "27/27 [==============================] - 44s 2s/step - loss: 0.3539 - f1_metric: 0.7092 - val_loss: 0.4925 - val_f1_metric: 0.2419\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3045 - f1_metric: 0.7409\n",
      "Epoch 5: val_f1_metric did not improve from 0.44534\n",
      "27/27 [==============================] - 49s 2s/step - loss: 0.3045 - f1_metric: 0.7409 - val_loss: 0.4506 - val_f1_metric: 0.3455\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2652 - f1_metric: 0.7823\n",
      "Epoch 6: val_f1_metric did not improve from 0.44534\n",
      "27/27 [==============================] - 50s 2s/step - loss: 0.2652 - f1_metric: 0.7823 - val_loss: 0.3992 - val_f1_metric: 0.4210\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2335 - f1_metric: 0.8046\n",
      "Epoch 7: val_f1_metric did not improve from 0.44534\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.2335 - f1_metric: 0.8046 - val_loss: 0.4161 - val_f1_metric: 0.2775\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2064 - f1_metric: 0.8315\n",
      "Epoch 8: val_f1_metric improved from 0.44534 to 0.45791, saving model to best_model.h5\n",
      "27/27 [==============================] - 50s 2s/step - loss: 0.2064 - f1_metric: 0.8315 - val_loss: 0.3738 - val_f1_metric: 0.4579\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1754 - f1_metric: 0.8613\n",
      "Epoch 9: val_f1_metric improved from 0.45791 to 0.56667, saving model to best_model.h5\n",
      "27/27 [==============================] - 46s 2s/step - loss: 0.1754 - f1_metric: 0.8613 - val_loss: 0.3392 - val_f1_metric: 0.5667\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1475 - f1_metric: 0.8892\n",
      "Epoch 10: val_f1_metric improved from 0.56667 to 0.58089, saving model to best_model.h5\n",
      "27/27 [==============================] - 42s 2s/step - loss: 0.1475 - f1_metric: 0.8892 - val_loss: 0.3407 - val_f1_metric: 0.5809\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1318 - f1_metric: 0.9061\n",
      "Epoch 11: val_f1_metric improved from 0.58089 to 0.58791, saving model to best_model.h5\n",
      "27/27 [==============================] - 41s 1s/step - loss: 0.1318 - f1_metric: 0.9061 - val_loss: 0.3283 - val_f1_metric: 0.5879\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1190 - f1_metric: 0.9163\n",
      "Epoch 12: val_f1_metric improved from 0.58791 to 0.69147, saving model to best_model.h5\n",
      "27/27 [==============================] - 32s 1s/step - loss: 0.1190 - f1_metric: 0.9163 - val_loss: 0.2930 - val_f1_metric: 0.6915\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1133 - f1_metric: 0.9148\n",
      "Epoch 13: val_f1_metric improved from 0.69147 to 0.73880, saving model to best_model.h5\n",
      "27/27 [==============================] - 42s 2s/step - loss: 0.1133 - f1_metric: 0.9148 - val_loss: 0.2876 - val_f1_metric: 0.7388\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0904 - f1_metric: 0.9280\n",
      "Epoch 14: val_f1_metric did not improve from 0.73880\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0904 - f1_metric: 0.9280 - val_loss: 0.3461 - val_f1_metric: 0.7051\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0809 - f1_metric: 0.9441\n",
      "Epoch 15: val_f1_metric did not improve from 0.73880\n",
      "27/27 [==============================] - 53s 2s/step - loss: 0.0809 - f1_metric: 0.9441 - val_loss: 0.3630 - val_f1_metric: 0.6901\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0724 - f1_metric: 0.9575\n",
      "Epoch 16: val_f1_metric did not improve from 0.73880\n",
      "27/27 [==============================] - 46s 2s/step - loss: 0.0724 - f1_metric: 0.9575 - val_loss: 0.3304 - val_f1_metric: 0.7161\n",
      "Epoch 17/100\n",
      " 4/27 [===>..........................] - ETA: 45s - loss: 0.0465 - f1_metric: 0.9801"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1_metric\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, patience\u001b[38;5;241m=\u001b[39mpatience)\n\u001b[0;32m     12\u001b[0m mc \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1_metric\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmyModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m milli_sec2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining is completed after\u001b[39m\u001b[38;5;124m\"\u001b[39m, milli_sec2\u001b[38;5;241m-\u001b[39mmilli_sec1)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "milli_sec1 = int(round(time.time() * 1000))\n",
    "\n",
    "if userModel == \"cnn\":\n",
    "    myModel = buildCnn(max_length, num_words, dim, optimizer, seed, embedding_matrix, False, 1) \n",
    "elif userModel == \"lstm\":\n",
    "    myModel = buildLstm(max_length, num_words, dim, optimizer, seed, embedding_matrix, False, 1)\n",
    "print(\"model summary\\m\",myModel.summary())\n",
    "\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=',')\n",
    "es = EarlyStopping(monitor='val_f1_metric', mode='max', verbose=1, patience=patience)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_f1_metric', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "history = myModel.fit(x_train, y_train, validation_data=(x_val, y_val), epochs = n_epoch, batch_size = batch_size, verbose=1, callbacks=[csv_logger,es,mc])\n",
    "\n",
    "milli_sec2 = int(round(time.time() * 1000))\n",
    "print(\"Training is completed after\", milli_sec2-milli_sec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387b315-e5d5-4b12-8acb-679183b1762f",
   "metadata": {},
   "source": [
    "Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0199a0c9-3c4b-4226-b54a-9ac9c998f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90781fe",
   "metadata": {},
   "source": [
    "Make predictions on the testing set and compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c019f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 3s 85ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       319\n",
      "           1       0.78      0.62      0.69       100\n",
      "\n",
      "    accuracy                           0.87       419\n",
      "   macro avg       0.83      0.78      0.80       419\n",
      "weighted avg       0.86      0.87      0.86       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predScores = myModel.predict(x_test)\n",
    "predictions = (predScores > 0.5).astype(\"int32\")\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12c1d9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP= 62\n",
      "TN= 301\n",
      "FP= 18\n",
      "FN= 38\n",
      "Accuracy:86.63%\n",
      "Precision:77.50%\n",
      "Recall:62.00%\n",
      "Roc_Auc score:78.18%\n",
      "F1 score:68.89%\n",
      "F2 score:64.58%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test, predictions)\n",
    "precision=precision_score(y_test, predictions)\n",
    "recall=recall_score(y_test, predictions)\n",
    "roc_auc=roc_auc_score(y_test, predictions)\n",
    "f1=f1_score(y_test, predictions)\n",
    "f2 = (5*precision*recall) / (4*precision+recall)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "sn.heatmap(conf_matrix, annot=True)\n",
    "\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "acc = ((tp+tn)/(tp+tn+fp+fn))\n",
    "print(\"TP=\",tp)\n",
    "print(\"TN=\",tn)\n",
    "print(\"FP=\",fp)\n",
    "print(\"FN=\",fn)\n",
    "\n",
    "print(\"Accuracy:%.2f%%\"%(accuracy*100))\n",
    "print(\"Precision:%.2f%%\"%(precision*100))\n",
    "print(\"Recall:%.2f%%\"%(recall*100))\n",
    "print(\"Roc_Auc score:%.2f%%\"%(roc_auc*100))\n",
    "print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "print(\"F2 score:%.2f%%\"%(f2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb15c5f-81f4-4be9-a1ff-1b1b7c0c6d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
