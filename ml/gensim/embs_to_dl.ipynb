{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007b5205",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52dd00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import json, os, io\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, \\\n",
    "roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.layers import Embedding, MaxPool1D\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.initializers import glorot_uniform, RandomUniform, lecun_uniform, Constant\n",
    "from collections import OrderedDict\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, GlobalMaxPool1D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool1D\n",
    "from keras_preprocessing.text import tokenizer_from_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f55447",
   "metadata": {},
   "source": [
    "Specify a constant seeder for processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbb1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219c4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropEmpty(tokens0):\n",
    "    tokens = []\n",
    "    for i in range(0, len(tokens0)):\n",
    "        temp = tokens0[i]\n",
    "        if temp != []:\n",
    "            tokens.append(temp)\n",
    "    return tokens\n",
    "\n",
    "def listToString(s): \n",
    "    \n",
    "    # initialize an empty string\n",
    "    str1 = \"\" \n",
    "    \n",
    "    # traverse in the string \n",
    "    count = 0\n",
    "    for ele in s: \n",
    "        if count==0:\n",
    "            str1 = str1 + ele\n",
    "        else:\n",
    "            str1 = str1 + ' ' + ele\n",
    "        count = count + 1\n",
    "        #str1 += ele  \n",
    "    \n",
    "    # return string  \n",
    "    return str1\n",
    "\n",
    "def prepareData(data):\n",
    "        \n",
    "    # lowercase\n",
    "    lines = []\n",
    "    labels = []\n",
    "    headlines = []\n",
    "    for i in range(0, len(data)):\n",
    "        labels.append(int(data[i][1]))\n",
    "        headlines.append(data[i][0])\n",
    "        line = data[i][2:]\n",
    "        lows = [w.lower() for w in line]\n",
    "        lines.append(lows)\n",
    "    \n",
    "    texts = []\n",
    "    for i in range(0, len(lines)):\n",
    "        texts.append(listToString(lines[i]))\n",
    "    \n",
    "    return texts, labels, headlines "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88221c5a",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6af2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join('..', '..')\n",
    "with open(os.path.join(root_path, 'data', 'dataset.csv'), newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "data = dropEmpty(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff99988",
   "metadata": {},
   "source": [
    "Shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06f1a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf95bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels, headlines = prepareData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e09f413",
   "metadata": {},
   "source": [
    "Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479d07b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements in dataset: 4184\n",
      "2 categories found:\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABmIAAAKOCAYAAAC1CQadAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1/UlEQVR4nO3df5BV9X3/8dcVZIMGbgXcXbZuDJkQooHYFi1CE0VFhIZQk0w0obOjo/FH/DUEHH9l0phOKmonYqc0xtgk1l81nTYkdjRErEokiD9oaNSoNY1OYGRFk2UXDFkI3u8f+XonC2p05cNl4fGYuTPcc9579338KzvPnHsqtVqtFgAAAAAAAHa6fRq9AAAAAAAAwJ5KiAEAAAAAAChEiAEAAAAAAChEiAEAAAAAAChEiAEAAAAAAChEiAEAAAAAAChEiAEAAAAAAChkcKMXGCheeeWVPP/88xk2bFgqlUqj1wEAAAAAABqoVqtl48aNaWtryz77vP59L0LMm/T888+nvb290WsAAAAAAAC7kTVr1uSggw563fNCzJs0bNiwJL/7Dzp8+PAGbwMAAAAAADRST09P2tvb6/3g9Qgxb9KrX0c2fPhwIQYAAAAAAEiSP/g4k9f/0jIAAAAAAADeFiEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgECEGAAAAAACgkMGNXoCB792X3NnoFQAA6IfnrvxIo1cAAADY47kjBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoBAhBgAAAAAAoJCGhpjrrrsuH/zgBzN8+PAMHz48kydPzve///36+VqtlssvvzxtbW0ZOnRopk6dmieeeKLPZ/T29ub888/PqFGjsv/++2f27NlZu3Ztn5murq50dHSkWq2mWq2mo6MjGzZs2BWXCAAAAAAA7MUaGmIOOuigXHnllXn00Ufz6KOP5thjj81f/dVf1WPL1VdfnWuuuSaLFi3KI488ktbW1hx//PHZuHFj/TPmzp2bxYsX5/bbb8/y5cuzadOmzJo1K9u2bavPzJkzJ6tXr86SJUuyZMmSrF69Oh0dHbv8egEAAAAAgL1LpVar1Rq9xO8bMWJE/v7v/z6nnXZa2traMnfu3Fx88cVJfnf3S0tLS6666qqcddZZ6e7uzoEHHpibb745J598cpLk+eefT3t7e+66666ccMIJefLJJ3PooYdm5cqVmTRpUpJk5cqVmTx5cp566qmMGzfuTe3V09OTarWa7u7uDB8+vMzFD1DvvuTORq8AAEA/PHflRxq9AgAAwID1ZrvBbvOMmG3btuX222/Pyy+/nMmTJ+fZZ59NZ2dnpk+fXp9pamrK0UcfnRUrViRJVq1ala1bt/aZaWtry/jx4+szDz74YKrVaj3CJMmRRx6ZarVan3ktvb296enp6fMCAAAAAAB4KxoeYh577LG8853vTFNTU84+++wsXrw4hx56aDo7O5MkLS0tfeZbWlrq5zo7OzNkyJAccMABbzjT3Ny8w+9tbm6uz7yWBQsW1J8pU61W097e/rauEwAAAAAA2Ps0PMSMGzcuq1evzsqVK/PZz342p5xySn7605/Wz1cqlT7ztVpth2Pb237mteb/0Odceuml6e7urr/WrFnzZi8JAAAAAAAgyW4QYoYMGZL3vve9Ofzww7NgwYIcdthh+Yd/+Ie0trYmyQ53raxfv75+l0xra2u2bNmSrq6uN5x54YUXdvi9L7744g532/y+pqamDB8+vM8LAAAAAADgrWh4iNlerVZLb29vxowZk9bW1ixdurR+bsuWLVm2bFmmTJmSJJk4cWL23XffPjPr1q3L448/Xp+ZPHlyuru78/DDD9dnHnrooXR3d9dnAAAAAAAAShjcyF9+2WWXZebMmWlvb8/GjRtz++235/7778+SJUtSqVQyd+7cXHHFFRk7dmzGjh2bK664Ivvtt1/mzJmTJKlWqzn99NMzf/78jBw5MiNGjMiFF16YCRMmZNq0aUmSQw45JDNmzMgZZ5yR66+/Pkly5plnZtasWRk3blzDrh0AAAAAANjzNTTEvPDCC+no6Mi6detSrVbzwQ9+MEuWLMnxxx+fJLnooouyefPmnHPOOenq6sqkSZNy9913Z9iwYfXPWLhwYQYPHpyTTjopmzdvznHHHZcbb7wxgwYNqs/ceuutueCCCzJ9+vQkyezZs7No0aJde7EAAAAAAMBep1Kr1WqNXmIg6OnpSbVaTXd3t+fFbOfdl9zZ6BUAAOiH5678SKNXAAAAGLDebDfY7Z4RAwAAAAAAsKcQYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAoRYgAAAAAAAAppaIhZsGBBjjjiiAwbNizNzc058cQT8/TTT/eZOfXUU1OpVPq8jjzyyD4zvb29Of/88zNq1Kjsv//+mT17dtauXdtnpqurKx0dHalWq6lWq+no6MiGDRtKXyIAAAAAALAXa2iIWbZsWc4999ysXLkyS5cuzW9/+9tMnz49L7/8cp+5GTNmZN26dfXXXXfd1ef83Llzs3jx4tx+++1Zvnx5Nm3alFmzZmXbtm31mTlz5mT16tVZsmRJlixZktWrV6ejo2OXXCcAAAAAALB3GtzIX75kyZI+77/1rW+lubk5q1atylFHHVU/3tTUlNbW1tf8jO7u7nzjG9/IzTffnGnTpiVJbrnllrS3t+eee+7JCSeckCeffDJLlizJypUrM2nSpCTJDTfckMmTJ+fpp5/OuHHjCl0hAAAAAACwN9utnhHT3d2dJBkxYkSf4/fff3+am5vzvve9L2eccUbWr19fP7dq1aps3bo106dPrx9ra2vL+PHjs2LFiiTJgw8+mGq1Wo8wSXLkkUemWq3WZ7bX29ubnp6ePi8AAAAAAIC3YrcJMbVaLfPmzcuHPvShjB8/vn585syZufXWW3PvvffmK1/5Sh555JEce+yx6e3tTZJ0dnZmyJAhOeCAA/p8XktLSzo7O+szzc3NO/zO5ubm+sz2FixYUH+eTLVaTXt7+866VAAAAAAAYC/R0K8m+33nnXdefvKTn2T58uV9jp988sn1f48fPz6HH354Dj744Nx55535+Mc//rqfV6vVUqlU6u9//9+vN/P7Lr300sybN6/+vqenR4wBAAAAAADekt3ijpjzzz8/d9xxR+67774cdNBBbzg7evToHHzwwXnmmWeSJK2trdmyZUu6urr6zK1fvz4tLS31mRdeeGGHz3rxxRfrM9tramrK8OHD+7wAAAAAAADeioaGmFqtlvPOOy/f+c53cu+992bMmDF/8Gd++ctfZs2aNRk9enSSZOLEidl3332zdOnS+sy6devy+OOPZ8qUKUmSyZMnp7u7Ow8//HB95qGHHkp3d3d9BgAAAAAAYGdr6FeTnXvuubntttvyve99L8OGDas/r6VarWbo0KHZtGlTLr/88nziE5/I6NGj89xzz+Wyyy7LqFGj8rGPfaw+e/rpp2f+/PkZOXJkRowYkQsvvDATJkzItGnTkiSHHHJIZsyYkTPOOCPXX399kuTMM8/MrFmzMm7cuMZcPAAAAAAAsMdraIi57rrrkiRTp07tc/xb3/pWTj311AwaNCiPPfZYbrrppmzYsCGjR4/OMccck29/+9sZNmxYfX7hwoUZPHhwTjrppGzevDnHHXdcbrzxxgwaNKg+c+utt+aCCy7I9OnTkySzZ8/OokWLyl8kAAAAAACw16rUarVao5cYCHp6elKtVtPd3e15Mdt59yV3NnoFAAD64bkrP9LoFQAAAAasN9sNGvqMGAAAAAAAgD2ZEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFCIEAMAAAAAAFBIQ0PMggULcsQRR2TYsGFpbm7OiSeemKeffrrPTK1Wy+WXX562trYMHTo0U6dOzRNPPNFnpre3N+eff35GjRqV/fffP7Nnz87atWv7zHR1daWjoyPVajXVajUdHR3ZsGFD6UsEAAAAAAD2Yg0NMcuWLcu5556blStXZunSpfntb3+b6dOn5+WXX67PXH311bnmmmuyaNGiPPLII2ltbc3xxx+fjRs31mfmzp2bxYsX5/bbb8/y5cuzadOmzJo1K9u2bavPzJkzJ6tXr86SJUuyZMmSrF69Oh0dHbv0egEAAAAAgL1LpVar1Rq9xKtefPHFNDc3Z9myZTnqqKNSq9XS1taWuXPn5uKLL07yu7tfWlpactVVV+Wss85Kd3d3DjzwwNx88805+eSTkyTPP/982tvbc9ddd+WEE07Ik08+mUMPPTQrV67MpEmTkiQrV67M5MmT89RTT2XcuHF/cLeenp5Uq9V0d3dn+PDh5f4jDEDvvuTORq8AAEA/PHflRxq9AgAAwID1ZrvBbvWMmO7u7iTJiBEjkiTPPvtsOjs7M3369PpMU1NTjj766KxYsSJJsmrVqmzdurXPTFtbW8aPH1+fefDBB1OtVusRJkmOPPLIVKvV+sz2ent709PT0+cFAAAAAADwVuw2IaZWq2XevHn50Ic+lPHjxydJOjs7kyQtLS19ZltaWurnOjs7M2TIkBxwwAFvONPc3LzD72xubq7PbG/BggX158lUq9W0t7e/vQsEAAAAAAD2OrtNiDnvvPPyk5/8JP/6r/+6w7lKpdLnfa1W2+HY9rafea35N/qcSy+9NN3d3fXXmjVr3sxlAAAAAAAA1O0WIeb888/PHXfckfvuuy8HHXRQ/Xhra2uS7HDXyvr16+t3ybS2tmbLli3p6up6w5kXXnhhh9/74osv7nC3zauampoyfPjwPi8AAAAAAIC3oqEhplar5bzzzst3vvOd3HvvvRkzZkyf82PGjElra2uWLl1aP7Zly5YsW7YsU6ZMSZJMnDgx++67b5+ZdevW5fHHH6/PTJ48Od3d3Xn44YfrMw899FC6u7vrMwAAAAAAADvb4Eb+8nPPPTe33XZbvve972XYsGH1O1+q1WqGDh2aSqWSuXPn5oorrsjYsWMzduzYXHHFFdlvv/0yZ86c+uzpp5+e+fPnZ+TIkRkxYkQuvPDCTJgwIdOmTUuSHHLIIZkxY0bOOOOMXH/99UmSM888M7Nmzcq4ceMac/EAAAAAAMAer6Eh5rrrrkuSTJ06tc/xb33rWzn11FOTJBdddFE2b96cc845J11dXZk0aVLuvvvuDBs2rD6/cOHCDB48OCeddFI2b96c4447LjfeeGMGDRpUn7n11ltzwQUXZPr06UmS2bNnZ9GiRWUvEAAAAAAA2KtVarVardFLDAQ9PT2pVqvp7u72vJjtvPuSOxu9AgAA/fDclR9p9AoAAAAD1pvtBg19RgwAAAAAAMCeTIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAoRIgBAAAAAAAopF8hZs2aNVm7dm39/cMPP5y5c+fm61//+k5bDAAAAAAAYKDrV4iZM2dO7rvvviRJZ2dnjj/++Dz88MO57LLL8rd/+7c7dUEAAAAAAICBql8h5vHHH8+f//mfJ0n+7d/+LePHj8+KFSty22235cYbb9yZ+wEAAAAAAAxY/QoxW7duTVNTU5LknnvuyezZs5Mk73//+7Nu3bqdtx0AAAAAAMAA1q8Q84EPfCBf+9rX8sADD2Tp0qWZMWNGkuT555/PyJEjd+qCAAAAAAAAA1W/QsxVV12V66+/PlOnTs2nP/3pHHbYYUmSO+64o/6VZQAAAAAAAHu7wf35oalTp+all15KT09PDjjggPrxM888M/vvv/9OWw4AAAAAAGAg69cdMccee2w2btzYJ8IkyYgRI3LyySfvlMUAAAAAAAAGun6FmPvvvz9btmzZ4fhvfvObPPDAA297KQAAAAAAgD3BW/pqsp/85Cf1f//0pz9NZ2dn/f22bduyZMmS/PEf//HO2w4AAAAAAGAAe0sh5k/+5E9SqVRSqVRy7LHH7nB+6NCh+cd//MedthwAAAAAAMBA9pZCzLPPPptarZb3vOc9efjhh3PggQfWzw0ZMiTNzc0ZNGjQTl8SAAAAAABgIHpLIebggw9OkrzyyitFlgEAAAAAANiTvKUQ8/v+93//N/fff3/Wr1+/Q5j5m7/5m7e9GAAAAAAAwEDXrxBzww035LOf/WxGjRqV1tbWVCqV+rlKpSLEAAAAAAAApJ8h5stf/nL+7u/+LhdffPHO3gcAAAAAAGCPsU9/fqirqyuf/OQnd/YuAAAAAAAAe5R+hZhPfvKTufvuu3f2LgAAAAAAAHuUfn012Xvf+9584QtfyMqVKzNhwoTsu+++fc5fcMEFO2U5AAAAAACAgaxSq9Vqb/WHxowZ8/ofWKnk5z//+dtaanfU09OTarWa7u7uDB8+vNHr7FbefcmdjV4BAIB+eO7KjzR6BQAAgAHrzXaDft0R8+yzz/Z7MQAAAAAAgL1Fv54RAwAAAAAAwB/WrztiTjvttDc8/81vfrNfywAAAAAAAOxJ+hViurq6+rzfunVrHn/88WzYsCHHHnvsTlkMAAAAAABgoOtXiFm8ePEOx1555ZWcc845ec973vO2lwIAAAAAANgT7LRnxOyzzz753Oc+l4ULF+6sjwQAAAAAABjQdlqISZL/+7//y29/+9ud+ZEAAAAAAAADVr++mmzevHl93tdqtaxbty533nlnTjnllJ2yGAAAAAAAwEDXrxDz4x//uM/7ffbZJwceeGC+8pWv5LTTTtspiwEAAAAAAAx0/Qox9913387eAwAAAAAAYI/TrxDzqhdffDFPP/10KpVK3ve+9+XAAw/cWXsBAAAAAAAMePv054defvnlnHbaaRk9enSOOuqofPjDH05bW1tOP/30/PrXv97ZOwIAAAAAAAxI/Qox8+bNy7Jly/Kf//mf2bBhQzZs2JDvfe97WbZsWebPn7+zdwQAAAAAABiQ+vXVZP/xH/+Rf//3f8/UqVPrx/7yL/8yQ4cOzUknnZTrrrtuZ+0HAAAAAAAwYPXrjphf//rXaWlp2eF4c3OzryYDAAAAAAD4//oVYiZPnpwvfvGL+c1vflM/tnnz5nzpS1/K5MmTd9pyAAAAAAAAA1m/vprs2muvzcyZM3PQQQflsMMOS6VSyerVq9PU1JS77757Z+8IAAAAAAAwIPUrxEyYMCHPPPNMbrnlljz11FOp1Wr51Kc+lb/+67/O0KFDd/aOAAAAAAAAA1K/QsyCBQvS0tKSM844o8/xb37zm3nxxRdz8cUX75TlAAAAAAAABrJ+PSPm+uuvz/vf//4djn/gAx/I1772tbe9FAAAAAAAwJ6gXyGms7Mzo0eP3uH4gQcemHXr1r3tpQAAAAAAAPYE/Qox7e3t+dGPfrTD8R/96Edpa2t720sBAAAAAADsCfr1jJjPfOYzmTt3brZu3Zpjjz02SfJf//VfueiiizJ//vyduiAAAAAAAMBA1a8Qc9FFF+VXv/pVzjnnnGzZsiVJ8o53vCMXX3xxLr300p26IAAAAAAAwEDVrxBTqVRy1VVX5Qtf+EKefPLJDB06NGPHjk1TU9PO3g8AAAAAAGDA6leIedU73/nOHHHEETtrFwAAAAAAgD3KPo1eAAAAAAAAYE8lxAAAAAAAABTS0BDzwx/+MB/96EfT1taWSqWS7373u33On3rqqalUKn1eRx55ZJ+Z3t7enH/++Rk1alT233//zJ49O2vXru0z09XVlY6OjlSr1VSr1XR0dGTDhg2Frw4AAAAAANjbNTTEvPzyyznssMOyaNGi152ZMWNG1q1bV3/dddddfc7PnTs3ixcvzu23357ly5dn06ZNmTVrVrZt21afmTNnTlavXp0lS5ZkyZIlWb16dTo6OopdFwAAAAAAQJIMbuQvnzlzZmbOnPmGM01NTWltbX3Nc93d3fnGN76Rm2++OdOmTUuS3HLLLWlvb88999yTE044IU8++WSWLFmSlStXZtKkSUmSG264IZMnT87TTz+dcePG7dyLAgAAAAAA+P92+2fE3H///Wlubs773ve+nHHGGVm/fn393KpVq7J169ZMnz69fqytrS3jx4/PihUrkiQPPvhgqtVqPcIkyZFHHplqtVqfeS29vb3p6enp8wIAAAAAAHgrdusQM3PmzNx66625995785WvfCWPPPJIjj322PT29iZJOjs7M2TIkBxwwAF9fq6lpSWdnZ31mebm5h0+u7m5uT7zWhYsWFB/pky1Wk17e/tOvDIAAAAAAGBv0NCvJvtDTj755Pq/x48fn8MPPzwHH3xw7rzzznz84x9/3Z+r1WqpVCr197//79eb2d6ll16aefPm1d/39PSIMQAAAAAAwFuyW98Rs73Ro0fn4IMPzjPPPJMkaW1tzZYtW9LV1dVnbv369WlpaanPvPDCCzt81osvvlifeS1NTU0ZPnx4nxcAAAAAAMBbMaBCzC9/+cusWbMmo0ePTpJMnDgx++67b5YuXVqfWbduXR5//PFMmTIlSTJ58uR0d3fn4Ycfrs889NBD6e7urs8AAAAAAACU0NCvJtu0aVN+9rOf1d8/++yzWb16dUaMGJERI0bk8ssvzyc+8YmMHj06zz33XC677LKMGjUqH/vYx5Ik1Wo1p59+eubPn5+RI0dmxIgRufDCCzNhwoRMmzYtSXLIIYdkxowZOeOMM3L99dcnSc4888zMmjUr48aN2/UXDQAAAAAA7DUaGmIeffTRHHPMMfX3rz6T5ZRTTsl1112Xxx57LDfddFM2bNiQ0aNH55hjjsm3v/3tDBs2rP4zCxcuzODBg3PSSSdl8+bNOe6443LjjTdm0KBB9Zlbb701F1xwQaZPn54kmT17dhYtWrSLrhIAAAAAANhbVWq1Wq3RSwwEPT09qVar6e7u9ryY7bz7kjsbvQIAAP3w3JUfafQKAAAAA9ab7QYD6hkxAAAAAAAAA4kQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUIgQAwAAAAAAUEhDQ8wPf/jDfPSjH01bW1sqlUq++93v9jlfq9Vy+eWXp62tLUOHDs3UqVPzxBNP9Jnp7e3N+eefn1GjRmX//ffP7Nmzs3bt2j4zXV1d6ejoSLVaTbVaTUdHRzZs2FD46gAAAAAAgL1dQ0PMyy+/nMMOOyyLFi16zfNXX311rrnmmixatCiPPPJIWltbc/zxx2fjxo31mblz52bx4sW5/fbbs3z58mzatCmzZs3Ktm3b6jNz5szJ6tWrs2TJkixZsiSrV69OR0dH8esDAAAAAAD2bpVarVZr9BJJUqlUsnjx4px44olJfnc3TFtbW+bOnZuLL744ye/ufmlpaclVV12Vs846K93d3TnwwANz88035+STT06SPP/882lvb89dd92VE044IU8++WQOPfTQrFy5MpMmTUqSrFy5MpMnT85TTz2VcePGvan9enp6Uq1W093dneHDh+/8/wAD2LsvubPRKwAA0A/PXfmRRq8AAAAwYL3ZbrDbPiPm2WefTWdnZ6ZPn14/1tTUlKOPPjorVqxIkqxatSpbt27tM9PW1pbx48fXZx588MFUq9V6hEmSI488MtVqtT7zWnp7e9PT09PnBQAAAAAA8FbstiGms7MzSdLS0tLneEtLS/1cZ2dnhgwZkgMOOOANZ5qbm3f4/Obm5vrMa1mwYEH9mTLVajXt7e1v63oAAAAAAIC9z+BGL/CHVCqVPu9rtdoOx7a3/cxrzf+hz7n00kszb968+vuenh4xBgAA4G3wtcYAAAOTrzV+e3bbO2JaW1uTZIe7VtavX1+/S6a1tTVbtmxJV1fXG8688MILO3z+iy++uMPdNr+vqakpw4cP7/MCAAAAAAB4K3bbEDNmzJi0trZm6dKl9WNbtmzJsmXLMmXKlCTJxIkTs++++/aZWbduXR5//PH6zOTJk9Pd3Z2HH364PvPQQw+lu7u7PgMAAAAAAFBCQ7+abNOmTfnZz35Wf//ss89m9erVGTFiRN71rndl7ty5ueKKKzJ27NiMHTs2V1xxRfbbb7/MmTMnSVKtVnP66adn/vz5GTlyZEaMGJELL7wwEyZMyLRp05IkhxxySGbMmJEzzjgj119/fZLkzDPPzKxZszJu3Lhdf9EAAAAAAMBeo6Eh5tFHH80xxxxTf//qM1lOOeWU3HjjjbnooouyefPmnHPOOenq6sqkSZNy9913Z9iwYfWfWbhwYQYPHpyTTjopmzdvznHHHZcbb7wxgwYNqs/ceuutueCCCzJ9+vQkyezZs7No0aJddJUAAAAAAMDeqlKr1WqNXmIg6OnpSbVaTXd3t+fFbMcDNwEABiYP3GRX87cDAMDA5G+H1/Zmu8Fu+4wYAAAAAACAgU6IAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKESIAQAAAAAAKGS3DjGXX355KpVKn1dra2v9fK1Wy+WXX562trYMHTo0U6dOzRNPPNHnM3p7e3P++edn1KhR2X///TN79uysXbt2V18KAAAAAACwF9qtQ0ySfOADH8i6devqr8cee6x+7uqrr84111yTRYsW5ZFHHklra2uOP/74bNy4sT4zd+7cLF68OLfffnuWL1+eTZs2ZdasWdm2bVsjLgcAAAAAANiLDG70An/I4MGD+9wF86parZZrr702n//85/Pxj388SfIv//IvaWlpyW233Zazzjor3d3d+cY3vpGbb74506ZNS5LccsstaW9vzz333JMTTjhhl14LAAAAAACwd9nt74h55pln0tbWljFjxuRTn/pUfv7znydJnn322XR2dmb69On12aamphx99NFZsWJFkmTVqlXZunVrn5m2traMHz++PvN6ent709PT0+cFAAAAAADwVuzWIWbSpEm56aab8oMf/CA33HBDOjs7M2XKlPzyl79MZ2dnkqSlpaXPz7S0tNTPdXZ2ZsiQITnggANed+b1LFiwINVqtf5qb2/fiVcGAAAAAADsDXbrEDNz5sx84hOfyIQJEzJt2rTceeedSX73FWSvqlQqfX6mVqvtcGx7b2bm0ksvTXd3d/21Zs2afl4FAAAAAACwt9qtQ8z29t9//0yYMCHPPPNM/bkx29/Zsn79+vpdMq2trdmyZUu6urped+b1NDU1Zfjw4X1eAAAAAAAAb8WACjG9vb158sknM3r06IwZMyatra1ZunRp/fyWLVuybNmyTJkyJUkyceLE7Lvvvn1m1q1bl8cff7w+AwAAAAAAUMrgRi/wRi688MJ89KMfzbve9a6sX78+X/7yl9PT05NTTjkllUolc+fOzRVXXJGxY8dm7NixueKKK7Lffvtlzpw5SZJqtZrTTz898+fPz8iRIzNixIhceOGF9a86AwAAAAAAKGm3DjFr167Npz/96bz00ks58MADc+SRR2blypU5+OCDkyQXXXRRNm/enHPOOSddXV2ZNGlS7r777gwbNqz+GQsXLszgwYNz0kknZfPmzTnuuONy4403ZtCgQY26LAAAAAAAYC9RqdVqtUYvMRD09PSkWq2mu7vb82K28+5L7mz0CgAA9MNzV36k0Suwl/G3AwDAwORvh9f2ZrvBgHpGDAAAAAAAwEAixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABQixAAAAAAAABSyV4WYr371qxkzZkze8Y53ZOLEiXnggQcavRIAAAAAALAH22tCzLe//e3MnTs3n//85/PjH/84H/7whzNz5sz84he/aPRqAAAAAADAHmpwoxfYVa655pqcfvrp+cxnPpMkufbaa/ODH/wg1113XRYsWLDDfG9vb3p7e+vvu7u7kyQ9PT27ZuEB5JXeXzd6BQAA+sH/tmVX87cDAMDA5G+H1/bqf5darfaGc3tFiNmyZUtWrVqVSy65pM/x6dOnZ8WKFa/5MwsWLMiXvvSlHY63t7cX2REAAHa16rWN3gAAABgI/O3wxjZu3Jhqtfq65/eKEPPSSy9l27ZtaWlp6XO8paUlnZ2dr/kzl156aebNm1d//8orr+RXv/pVRo4cmUqlUnRfAHYPPT09aW9vz5o1azJ8+PBGrwMAAOym/O0AsHeq1WrZuHFj2tra3nBurwgxr9o+oNRqtdeNKk1NTWlqaupz7I/+6I9KrQbAbmz48OH+mAIAAP4gfzsA7H3e6E6YV+2zC/ZouFGjRmXQoEE73P2yfv36He6SAQAAAAAA2Fn2ihAzZMiQTJw4MUuXLu1zfOnSpZkyZUqDtgIAAAAAAPZ0e81Xk82bNy8dHR05/PDDM3ny5Hz961/PL37xi5x99tmNXg2A3VRTU1O++MUv7vBVlQAAAL/P3w4AvJFKrVarNXqJXeWrX/1qrr766qxbty7jx4/PwoULc9RRRzV6LQAAAAAAYA+1V4UYAAAAAACAXWmveEYMAAAAAABAIwgxAAAAAAAAhQgxAAAAAAAAhQgxAAAAAAAAhQgxAAAAAAAAhQxu9AIAsLtYu3ZtrrvuuqxYsSKdnZ2pVCppaWnJlClTcvbZZ6e9vb3RKwIAAAAwwFRqtVqt0UsAQKMtX748M2fOTHt7e6ZPn56WlpbUarWsX78+S5cuzZo1a/L9738/f/EXf9HoVQEAgN3cmjVr8sUvfjHf/OY3G70KALsBIQYAkhxxxBH50Ic+lIULF77m+c997nNZvnx5HnnkkV28GQAAMND8z//8T/7sz/4s27Zta/QqAOwGhBgASDJ06NCsXr0648aNe83zTz31VP70T/80mzdv3sWbAQAAu5s77rjjDc///Oc/z/z584UYAJJ4RgwAJElGjx6dFStWvG6IefDBBzN69OhdvBUAALA7OvHEE1OpVPJG///mSqWyCzcCYHcmxABAkgsvvDBnn312Vq1aleOPPz4tLS2pVCrp7OzM0qVL88///M+59tprG70mAACwGxg9enT+6Z/+KSeeeOJrnl+9enUmTpy4a5cCYLclxABAknPOOScjR47MwoULc/3119e/QmDQoEGZOHFibrrpppx00kkN3hIAANgdTJw4Mf/93//9uiHmD90tA8DexTNiAGA7W7duzUsvvZQkGTVqVPbdd98GbwQAAOxOHnjggbz88suZMWPGa55/+eWX8+ijj+boo4/exZsBsDsSYgAAAAAAAArZp9ELAAAAAAAA7KmEGAAAAAAAgEKEGAAAAAAAgEKEGAAAAAAAgEKEGAAAAAAAgEKEGAAAAAAAgEKEGAAAAAAAgEL+H4tnxwkx90vTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_elements=len(headlines)\n",
    "print('Elements in dataset:', n_elements)\n",
    "categories=sorted(list(set(labels))) #set will return the unique different entries\n",
    "n_categories=len(categories)\n",
    "print(\"{} categories found:\".format(n_categories))\n",
    "for category in categories:\n",
    "    print(category)\n",
    "    \n",
    "fig=plt.figure(figsize=(20,8))\n",
    "lbl, counts = np.unique(labels,return_counts=True)\n",
    "ticks = range(len(counts))\n",
    "plt.bar(ticks,counts, align='center')\n",
    "plt.xticks(ticks,lbl)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab7af89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class callbackmodule calls strid$ def __init__...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this_file os path abspath __file__ decode sys ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class migration migrations migration dependenc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset pd strid$ x dataset iloc numid$ values...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__metaclass__ type ansible_metadata strid$ str...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Labels\n",
       "0  class callbackmodule calls strid$ def __init__...       0\n",
       "1  this_file os path abspath __file__ decode sys ...       0\n",
       "2  class migration migrations migration dependenc...       0\n",
       "3  dataset pd strid$ x dataset iloc numid$ values...       1\n",
       "4  __metaclass__ type ansible_metadata strid$ str...       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(({'Text': texts, 'Labels': labels}))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679c62db-d0bb-4eb0-9fc0-5e64bbbbe4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of words per sequence: 510\n"
     ]
    }
   ],
   "source": [
    "word_counts = data[\"Text\"].apply(lambda x: len(x.split()))\n",
    "max_length = word_counts.max()\n",
    "print(\"Maximum number of words per sequence:\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c05ac3-b2ab-4e4d-bb13-975f69d26f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Frequencies:\n",
      " Labels\n",
      "0    3186\n",
      "1     998\n",
      "Name: count, dtype: int64\n",
      "Total samples  4184\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = data['Labels'].value_counts()\n",
    "print(\"Label Frequencies:\\n\", label_frequencies)\n",
    "print(\"Total samples \", len(data))\n",
    "n_categories = len(label_frequencies)\n",
    "print(\"Number of classes:\", n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c17e94d-d33a-4580-82f5-82694cdf418f",
   "metadata": {},
   "source": [
    "Create word embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ba78a0-056d-4cb8-9579-ccdc9cd07b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringToList(string):\n",
    "    codeLinesList = []\n",
    "    for line in string.split():\n",
    "        codeLinesList.append(line)\n",
    "    return codeLinesList\n",
    "\n",
    "allTokens = []\n",
    "for seq in data[\"Text\"]:\n",
    "    listSeq = stringToList(seq)\n",
    "    allTokens.append(listSeq)\n",
    "\n",
    "data[\"Tokens\"] = allTokens\n",
    "#data[\"Tokens\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8bde0a7-992d-4c62-a05b-7cf3894d782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embedding \n",
    "embeddings_index = {}\n",
    "f = open('w2v_embeddings.txt', encoding=\"utf-8\")\n",
    "for line in f:    \n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs   \n",
    "f.close() \n",
    "\n",
    "dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788c002f-2ba3-42da-831d-bfe27fbd53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_obj = Tokenizer()   \n",
    "tokenizer_obj.fit_on_texts(data[\"Tokens\"])\n",
    "\n",
    "tokenizer_json = tokenizer_obj.to_json()\n",
    "tokenizerFile = 'w2v_tokenizer.json'\n",
    "\n",
    "with io.open(tokenizerFile, 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "\n",
    "with open(tokenizerFile) as f:\n",
    "    dataTokenizer = json.load(f)\n",
    "    tokenizer_obj = tokenizer_from_json(dataTokenizer)\n",
    "\n",
    "sequences = tokenizer_obj.texts_to_sequences(data[\"Tokens\"])\n",
    "word_index = tokenizer_obj.word_index\n",
    "\n",
    "lines_pad = pad_sequences(sequences, padding = 'post', maxlen = max_length)\n",
    "\n",
    "num_words = len(word_index) + 1 # +1 for the unknown-zeros\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, dim))\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    #embedding_vector = embeddings_index.get(word)\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b6f1bb",
   "metadata": {},
   "source": [
    "Split to train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f3b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b54033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_x, test_x, train_val_y, test_y = train_test_split(lines_pad, data['Labels'], test_size=val_ratio, random_state=seed, stratify=data['Labels'])\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_val_x, train_val_y, test_size=val_ratio, random_state=seed, stratify=train_val_y)\n",
    "# print(len(data))\n",
    "# print(len(train_val_data))\n",
    "# print(len(test_data))\n",
    "# print(len(train_data))\n",
    "# print(len(val_data))\n",
    "# print(len(val_data)+len(train_data)+len(test_data))\n",
    "# print(len(val_data)+len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c93ea56e-8a53-40f7-96c5-96ef1421cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "x_train = train_x\n",
    "x_val = val_x\n",
    "x_test = test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1877644",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_y)\n",
    "y_val = np.array(val_y)\n",
    "y_test = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc7a662-c72d-4107-8858-a2294da5fb8d",
   "metadata": {},
   "source": [
    "Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1613b2a-b8d3-44d5-af45-eced7f1a5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions\n",
    "def recall_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f1 = 2*((prec*rec)/(prec+rec+K.epsilon()))\n",
    "    return f1\n",
    "\n",
    "def f2_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f2 = 5*((prec*rec)/(4*prec+rec+K.epsilon()))\n",
    "    return f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912029eb-5506-4dd3-b5d8-04d70baf6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def buildLstm(max_len, top_words, dim, optimizer, seed, embedding_matrix, multi, n_outputs):\n",
    "    model=Sequential()\n",
    "    #model.add(Embedding(input_dim=top_words+1, output_dim=dim, input_length=None, mask_zero=True))\n",
    "    model.add(Embedding(input_dim=top_words, output_dim=dim, input_length=None, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "    #model.add(SimpleRNN(300, dropout=0.3, stateful=False))\n",
    "    model.add(LSTM(100, dropout=0.2, return_sequences=True, stateful=False))\n",
    "    model.add(LSTM(50, dropout=0.1, stateful=False))\n",
    "    #model.add(Bidirectional(LSTM(300, dropout=0.3, stateful=False)))\n",
    "    #model.add(GRU(300, dropout=0.3, stateful=False))\n",
    "    model.add(Activation('relu')) #dropout=0.2, recurrent_dropout=0.2, kernel_constraint=max_norm(3), bias_constraint=max_norm(3)\n",
    "    model.add(BatchNormalization())\n",
    "    if multi == False:\n",
    "        model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[f1_metric])  \n",
    "    else: \n",
    "        model.add(Dense(n_outputs, activation='softmax'))\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "425ddd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "n_epoch = 100\n",
    "batch_size = 128\n",
    "optimizer = 'adam'\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1836761",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5da66cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 200)         2136600   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 100)         120400    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                30200     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 50)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 50)               200       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,287,451\n",
      "Trainable params: 150,751\n",
      "Non-trainable params: 2,136,700\n",
      "_________________________________________________________________\n",
      "model summary\\m None\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6160 - f1_metric: 0.5150\n",
      "Epoch 1: val_f1_metric improved from -inf to 0.59260, saving model to best_model.h5\n",
      "27/27 [==============================] - 65s 2s/step - loss: 0.6160 - f1_metric: 0.5150 - val_loss: 0.6118 - val_f1_metric: 0.5926\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4437 - f1_metric: 0.6671\n",
      "Epoch 2: val_f1_metric did not improve from 0.59260\n",
      "27/27 [==============================] - 39s 1s/step - loss: 0.4437 - f1_metric: 0.6671 - val_loss: 0.5360 - val_f1_metric: 0.5267\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3546 - f1_metric: 0.7542\n",
      "Epoch 3: val_f1_metric did not improve from 0.59260\n",
      "27/27 [==============================] - 43s 2s/step - loss: 0.3546 - f1_metric: 0.7542 - val_loss: 0.4757 - val_f1_metric: 0.5031\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2895 - f1_metric: 0.7894\n",
      "Epoch 4: val_f1_metric did not improve from 0.59260\n",
      "27/27 [==============================] - 43s 2s/step - loss: 0.2895 - f1_metric: 0.7894 - val_loss: 0.4296 - val_f1_metric: 0.5446\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2336 - f1_metric: 0.8336\n",
      "Epoch 5: val_f1_metric improved from 0.59260 to 0.64376, saving model to best_model.h5\n",
      "27/27 [==============================] - 53s 2s/step - loss: 0.2336 - f1_metric: 0.8336 - val_loss: 0.3798 - val_f1_metric: 0.6438\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2052 - f1_metric: 0.8664\n",
      "Epoch 6: val_f1_metric improved from 0.64376 to 0.66608, saving model to best_model.h5\n",
      "27/27 [==============================] - 50s 2s/step - loss: 0.2052 - f1_metric: 0.8664 - val_loss: 0.3515 - val_f1_metric: 0.6661\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1565 - f1_metric: 0.9013\n",
      "Epoch 7: val_f1_metric improved from 0.66608 to 0.73252, saving model to best_model.h5\n",
      "27/27 [==============================] - 39s 2s/step - loss: 0.1565 - f1_metric: 0.9013 - val_loss: 0.3305 - val_f1_metric: 0.7325\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1325 - f1_metric: 0.9082\n",
      "Epoch 8: val_f1_metric did not improve from 0.73252\n",
      "27/27 [==============================] - 54s 2s/step - loss: 0.1325 - f1_metric: 0.9082 - val_loss: 0.3079 - val_f1_metric: 0.7152\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1085 - f1_metric: 0.9199\n",
      "Epoch 9: val_f1_metric did not improve from 0.73252\n",
      "27/27 [==============================] - 48s 2s/step - loss: 0.1085 - f1_metric: 0.9199 - val_loss: 0.3022 - val_f1_metric: 0.7070\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0897 - f1_metric: 0.9395\n",
      "Epoch 10: val_f1_metric improved from 0.73252 to 0.74642, saving model to best_model.h5\n",
      "27/27 [==============================] - 43s 2s/step - loss: 0.0897 - f1_metric: 0.9395 - val_loss: 0.3137 - val_f1_metric: 0.7464\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0701 - f1_metric: 0.9585\n",
      "Epoch 11: val_f1_metric did not improve from 0.74642\n",
      "27/27 [==============================] - 44s 2s/step - loss: 0.0701 - f1_metric: 0.9585 - val_loss: 0.3002 - val_f1_metric: 0.7413\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0590 - f1_metric: 0.9623\n",
      "Epoch 12: val_f1_metric did not improve from 0.74642\n",
      "27/27 [==============================] - 35s 1s/step - loss: 0.0590 - f1_metric: 0.9623 - val_loss: 0.3343 - val_f1_metric: 0.7327\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0581 - f1_metric: 0.9638\n",
      "Epoch 13: val_f1_metric improved from 0.74642 to 0.74768, saving model to best_model.h5\n",
      "27/27 [==============================] - 45s 2s/step - loss: 0.0581 - f1_metric: 0.9638 - val_loss: 0.3115 - val_f1_metric: 0.7477\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0503 - f1_metric: 0.9707\n",
      "Epoch 14: val_f1_metric improved from 0.74768 to 0.76526, saving model to best_model.h5\n",
      "27/27 [==============================] - 39s 1s/step - loss: 0.0503 - f1_metric: 0.9707 - val_loss: 0.3336 - val_f1_metric: 0.7653\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0427 - f1_metric: 0.9761\n",
      "Epoch 15: val_f1_metric did not improve from 0.76526\n",
      "27/27 [==============================] - 54s 2s/step - loss: 0.0427 - f1_metric: 0.9761 - val_loss: 0.3932 - val_f1_metric: 0.7284\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0336 - f1_metric: 0.9784\n",
      "Epoch 16: val_f1_metric did not improve from 0.76526\n",
      "27/27 [==============================] - 48s 2s/step - loss: 0.0336 - f1_metric: 0.9784 - val_loss: 0.3955 - val_f1_metric: 0.7531\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0374 - f1_metric: 0.9748\n",
      "Epoch 17: val_f1_metric improved from 0.76526 to 0.77121, saving model to best_model.h5\n",
      "27/27 [==============================] - 47s 2s/step - loss: 0.0374 - f1_metric: 0.9748 - val_loss: 0.4094 - val_f1_metric: 0.7712\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0291 - f1_metric: 0.9800\n",
      "Epoch 18: val_f1_metric did not improve from 0.77121\n",
      "27/27 [==============================] - 46s 2s/step - loss: 0.0291 - f1_metric: 0.9800 - val_loss: 0.4024 - val_f1_metric: 0.7603\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0315 - f1_metric: 0.9816\n",
      "Epoch 19: val_f1_metric did not improve from 0.77121\n",
      "27/27 [==============================] - 43s 2s/step - loss: 0.0315 - f1_metric: 0.9816 - val_loss: 0.4591 - val_f1_metric: 0.7547\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0239 - f1_metric: 0.9871\n",
      "Epoch 20: val_f1_metric did not improve from 0.77121\n",
      "27/27 [==============================] - 49s 2s/step - loss: 0.0239 - f1_metric: 0.9871 - val_loss: 0.5038 - val_f1_metric: 0.7185\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0274 - f1_metric: 0.9841\n",
      "Epoch 21: val_f1_metric did not improve from 0.77121\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.0274 - f1_metric: 0.9841 - val_loss: 0.6014 - val_f1_metric: 0.7273\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0273 - f1_metric: 0.9827\n",
      "Epoch 22: val_f1_metric did not improve from 0.77121\n",
      "27/27 [==============================] - 50s 2s/step - loss: 0.0273 - f1_metric: 0.9827 - val_loss: 0.5250 - val_f1_metric: 0.7505\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0317 - f1_metric: 0.9768\n",
      "Epoch 23: val_f1_metric did not improve from 0.77121\n",
      "27/27 [==============================] - 44s 2s/step - loss: 0.0317 - f1_metric: 0.9768 - val_loss: 0.4501 - val_f1_metric: 0.7179\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0251 - f1_metric: 0.9804\n",
      "Epoch 24: val_f1_metric did not improve from 0.77121\n",
      "27/27 [==============================] - 48s 2s/step - loss: 0.0251 - f1_metric: 0.9804 - val_loss: 0.4933 - val_f1_metric: 0.7474\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0217 - f1_metric: 0.9887\n",
      "Epoch 25: val_f1_metric did not improve from 0.77121\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.0217 - f1_metric: 0.9887 - val_loss: 0.5817 - val_f1_metric: 0.7682\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0140 - f1_metric: 0.9924\n",
      "Epoch 26: val_f1_metric did not improve from 0.77121\n",
      "27/27 [==============================] - 53s 2s/step - loss: 0.0140 - f1_metric: 0.9924 - val_loss: 0.4750 - val_f1_metric: 0.7517\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0111 - f1_metric: 0.9944\n",
      "Epoch 27: val_f1_metric did not improve from 0.77121\n",
      "27/27 [==============================] - 52s 2s/step - loss: 0.0111 - f1_metric: 0.9944 - val_loss: 0.5084 - val_f1_metric: 0.7477\n",
      "Epoch 27: early stopping\n",
      "Training is completed after 1249454\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "milli_sec1 = int(round(time.time() * 1000))\n",
    "\n",
    "myModel = buildLstm(max_length, num_words, dim, optimizer, seed, embedding_matrix, False, 1)\n",
    "print(\"model summary\\m\",myModel.summary())\n",
    "\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=',')\n",
    "es = EarlyStopping(monitor='val_f1_metric', mode='max', verbose=1, patience=patience)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_f1_metric', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "history = myModel.fit(x_train, y_train, validation_data=(x_val, y_val), epochs = n_epoch, batch_size = batch_size, verbose=1, callbacks=[csv_logger,es,mc])\n",
    "\n",
    "milli_sec2 = int(round(time.time() * 1000))\n",
    "print(\"Training is completed after\", milli_sec2-milli_sec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387b315-e5d5-4b12-8acb-679183b1762f",
   "metadata": {},
   "source": [
    "Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0199a0c9-3c4b-4226-b54a-9ac9c998f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90781fe",
   "metadata": {},
   "source": [
    "Make predictions on the testing set and compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c019f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 3s 87ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       319\n",
      "           1       0.69      0.68      0.69       100\n",
      "\n",
      "    accuracy                           0.85       419\n",
      "   macro avg       0.80      0.79      0.79       419\n",
      "weighted avg       0.85      0.85      0.85       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predScores = myModel.predict(x_test)\n",
    "predictions = (predScores > 0.5).astype(\"int32\")\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12c1d9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP= 68\n",
      "TN= 289\n",
      "FP= 30\n",
      "FN= 32\n",
      "Accuracy:85.20%\n",
      "Precision:69.39%\n",
      "Recall:68.00%\n",
      "Roc_Auc score:79.30%\n",
      "F1 score:68.69%\n",
      "F2 score:68.27%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test, predictions)\n",
    "precision=precision_score(y_test, predictions)\n",
    "recall=recall_score(y_test, predictions)\n",
    "roc_auc=roc_auc_score(y_test, predictions)\n",
    "f1=f1_score(y_test, predictions)\n",
    "f2 = (5*precision*recall) / (4*precision+recall)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "sn.heatmap(conf_matrix, annot=True)\n",
    "\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "acc = ((tp+tn)/(tp+tn+fp+fn))\n",
    "print(\"TP=\",tp)\n",
    "print(\"TN=\",tn)\n",
    "print(\"FP=\",fp)\n",
    "print(\"FN=\",fn)\n",
    "\n",
    "print(\"Accuracy:%.2f%%\"%(accuracy*100))\n",
    "print(\"Precision:%.2f%%\"%(precision*100))\n",
    "print(\"Recall:%.2f%%\"%(recall*100))\n",
    "print(\"Roc_Auc score:%.2f%%\"%(roc_auc*100))\n",
    "print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "print(\"F2 score:%.2f%%\"%(f2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb15c5f-81f4-4be9-a1ff-1b1b7c0c6d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
