{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f17227",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900008db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import json, os\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool1D\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from transformers import GPT2Tokenizer, TFGPT2Model\n",
    "from transformers import set_seed\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, \\\n",
    "roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63adea57",
   "metadata": {},
   "source": [
    "Specify a constant seeder for processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800c219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90a033",
   "metadata": {},
   "source": [
    "Pre-trained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9e7f7d-445e-4ffb-8d51-3c5805c33917",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variation = \"microsoft/CodeGPT-small-py\"\n",
    "PAD_TOKEN = \"<|pad|>\"\n",
    "EOS_TOKEN = \"<|endoftext|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b9eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_variation, do_lower_case=True, pad_token=PAD_TOKEN,\n",
    "    eos_token=EOS_TOKEN)\n",
    "# gpt2 only NL\n",
    "# microsoft/CodeGPT-small-py only PL\n",
    "# microsoft/CodeGPT-small-py-adaptedGPT2 both NL and PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c41909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define New tokens for string and numerical i.e., strId$ and numId$\n",
    "new_tokens = [\"strId$\", \"numId$\"]\n",
    "for new_token in new_tokens:\n",
    "    if new_token not in tokenizer.get_vocab().keys():\n",
    "        tokenizer.add_tokens(new_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bab5f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f1 = 2*((prec*rec)/(prec+rec+K.epsilon()))\n",
    "    return f1\n",
    "\n",
    "def f2_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f2 = 5*((prec*rec)/(4*prec+rec+K.epsilon()))\n",
    "    return f2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc88923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropEmpty(tokens0):\n",
    "    tokens = []\n",
    "    for i in range(0, len(tokens0)):\n",
    "        temp = tokens0[i]\n",
    "        if temp != []:\n",
    "            tokens.append(temp)\n",
    "    return tokens\n",
    "\n",
    "def listToString(s): \n",
    "    \n",
    "    # initialize an empty string\n",
    "    str1 = \"\" \n",
    "    \n",
    "    # traverse in the string \n",
    "    count = 0\n",
    "    for ele in s: \n",
    "        if count==0:\n",
    "            str1 = str1 + ele\n",
    "        else:\n",
    "            str1 = str1 + ' ' + ele\n",
    "        count = count + 1\n",
    "        #str1 += ele  \n",
    "    \n",
    "    # return string  \n",
    "    return str1\n",
    "\n",
    "def prepareData(data):\n",
    "        \n",
    "    # lowercase\n",
    "    lines = []\n",
    "    labels = []\n",
    "    headlines = []\n",
    "    for i in range(0, len(data)):\n",
    "        labels.append(int(data[i][1]))\n",
    "        headlines.append(data[i][0])\n",
    "        line = data[i][2:]\n",
    "        lows = [w.lower() for w in line]\n",
    "        lines.append(lows)\n",
    "    \n",
    "    texts = []\n",
    "    for i in range(0, len(lines)):\n",
    "        texts.append(listToString(lines[i]))\n",
    "    \n",
    "    return texts, labels, headlines "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e066ad7",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59de311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join('..', '..')\n",
    "with open(os.path.join(root_path, 'data', 'dataset.csv'), newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "data = dropEmpty(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46988094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset\n",
    "random.shuffle(data)\n",
    "#data = data[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b5cddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels, headlines = prepareData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4dea5f",
   "metadata": {},
   "source": [
    "Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5c30885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements in dataset: 4184\n",
      "2 categories found:\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_elements=len(headlines)\n",
    "print('Elements in dataset:', n_elements)\n",
    "categories=sorted(list(set(labels))) #set will return the unique different entries\n",
    "n_categories=len(categories)\n",
    "print(\"{} categories found:\".format(n_categories))\n",
    "for category in categories:\n",
    "    print(category)\n",
    "    \n",
    "fig=plt.figure(figsize=(20,8))\n",
    "lbl, counts = np.unique(labels,return_counts=True)\n",
    "ticks = range(len(counts))\n",
    "plt.bar(ticks,counts, align='center')\n",
    "plt.xticks(ticks,lbl)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4ad0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(({'Text': texts, 'Labels': labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2f5a1",
   "metadata": {},
   "source": [
    "Split to train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d63e745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bafac0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_data, test_data = train_test_split(data, test_size=val_ratio, random_state=seed, stratify=data['Labels'])\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=val_ratio, random_state=seed, stratify=train_val_data['Labels'])\n",
    "# print(len(data))\n",
    "# print(len(train_val_data))\n",
    "# print(len(test_data))\n",
    "# print(len(train_data))\n",
    "# print(len(val_data))\n",
    "# print(len(val_data)+len(train_data)+len(test_data))\n",
    "# print(len(val_data)+len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52219ced",
   "metadata": {},
   "source": [
    "Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e72c2624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at microsoft/CodeGPT-small-py.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 50001, 'n_positions': 1024, 'n_embd': 768, 'n_layer': 12, 'n_head': 12, 'n_inner': None, 'activation_function': 'gelu_new', 'resid_pdrop': 0.1, 'embd_pdrop': 0.1, 'attn_pdrop': 0.1, 'layer_norm_epsilon': 1e-05, 'initializer_range': 0.02, 'summary_type': 'cls_index', 'summary_use_proj': True, 'summary_activation': None, 'summary_first_dropout': 0.1, 'summary_proj_to_labels': True, 'scale_attn_weights': True, 'use_cache': True, 'scale_attn_by_inverse_layer_idx': False, 'reorder_and_upcast_attn': False, 'bos_token_id': 0, 'eos_token_id': 50001, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['GPT2LMHeadModel'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'pad_token_id': 50003, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/CodeGPT-small-py', 'transformers_version': '4.40.2', '_num_labels': 2, 'model_type': 'gpt2', 'n_ctx': 1024, 'output_past': True}\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2Model.from_pretrained(model_variation,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id, num_labels=n_categories)\n",
    "\n",
    "model.training = True\n",
    "\n",
    "config = model.get_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd50559",
   "metadata": {},
   "source": [
    "Resize model embedding to match new tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e499ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x1a09b424be0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afdfd83",
   "metadata": {},
   "source": [
    "Compute maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed0b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxLen(X):\n",
    "\n",
    "    # Code for identifying max length of the data samples after tokenization using transformer tokenizer\n",
    "    \n",
    "    max_length = 0\n",
    "    # Iterate over each sample in your dataset\n",
    "    for i, input_ids in enumerate(X):\n",
    "        # Calculate the length of the tokenized sequence for the current sample\n",
    "        length = tf.math.reduce_sum(tf.cast(input_ids != 1, tf.int32)).numpy()\n",
    "        # Update max_length and max_row if the current length is greater\n",
    "        if length > max_length:\n",
    "            max_length = length\n",
    "            max_row = i\n",
    "\n",
    "    print(\"Max length of tokenized data:\", max_length)\n",
    "    print(\"Row with max length:\", max_row)\n",
    "\n",
    "    #X['input_ids'] = np.delete(X['input_ids'], max_row, axis=0)\n",
    "    \n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79e2105a-2279-4c6f-96de-7cbbd504cc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iliaskaloup\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of tokenized data: 512\n",
      "Row with max length: 0\n"
     ]
    }
   ],
   "source": [
    "X = [ex + EOS_TOKEN for ex in train_data['Text']]\n",
    "X_ = [tokenizer(x, return_tensors='tf', max_length=512, truncation=True, pad_to_max_length=True, add_special_tokens=True)['input_ids'] for x in X]\n",
    "X_in = tf.squeeze(tf.convert_to_tensor(X_), axis=1)\n",
    "max_len = getMaxLen(X_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa449f4",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfd8e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [ex + EOS_TOKEN for ex in train_data['Text']]\n",
    "X_train_ = [tokenizer(x, return_tensors='tf', max_length=max_len, truncation=True, pad_to_max_length=True, add_special_tokens=True)['input_ids'] for x in X_train]\n",
    "X_train_in = tf.squeeze(tf.convert_to_tensor(X_train_), axis=1)\n",
    "\n",
    "X_val = [ex + EOS_TOKEN for ex in val_data['Text']]\n",
    "X_val_ = [tokenizer(x, return_tensors='tf', max_length=max_len, truncation=True, pad_to_max_length=True, add_special_tokens=True)['input_ids'] for x in X_val]\n",
    "X_val_in = tf.squeeze(tf.convert_to_tensor(X_val_), axis=1)\n",
    "\n",
    "X_test = [ex + EOS_TOKEN for ex in test_data['Text']]\n",
    "X_test_ = [tokenizer(x, return_tensors='tf', max_length=max_len, truncation=True, pad_to_max_length=True, add_special_tokens=True)['input_ids'] for x in X_test]\n",
    "X_test_in = tf.squeeze(tf.convert_to_tensor(X_test_), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bc98f95-42d7-4738-912e-e8606b80be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mask_ = [tokenizer(x, return_tensors='tf', max_length=max_len, truncation=True, pad_to_max_length=True, add_special_tokens=True)[\"attention_mask\"] for x in X_train]\n",
    "X_train_mask = tf.squeeze(tf.convert_to_tensor(X_train_mask_), axis=1)\n",
    "\n",
    "X_val_mask_ = [tokenizer(x, return_tensors='tf', max_length=max_len, truncation=True, pad_to_max_length=True, add_special_tokens=True)[\"attention_mask\"] for x in X_val]\n",
    "X_val_mask = tf.squeeze(tf.convert_to_tensor(X_val_mask_), axis=1)\n",
    "\n",
    "X_test_mask_ = [tokenizer(x, return_tensors='tf', max_length=max_len, truncation=True, pad_to_max_length=True, add_special_tokens=True)[\"attention_mask\"] for x in X_test]\n",
    "X_test_mask = tf.squeeze(tf.convert_to_tensor(X_test_mask_), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f1c220-99cd-4e34-bf36-13e802d417e6",
   "metadata": {},
   "source": [
    "Set the GPT2 pre-trained layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "781997b7-9dac-4b29-ba38-a2fb0bd55a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cbf1a01-8662-49c3-9b35-cbb3ab5d3230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLaye  multiple                 124247040 \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,247,040\n",
      "Trainable params: 124,247,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a572bae-c6b2-46ed-a2bf-35ec0f808937",
   "metadata": {},
   "source": [
    "Next we build on top of GPT2. The model takes in tokens and mask tensors. The outputs are the last hidden states of the last layer in the transformer. These are reduced using the mean over the sequence length, passed through 2 dense layers with dopout in between. The output layer has X nodes (softmax activation function for probabilities) for the X classes we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a005c534-5b05-4f04-9543-e1bd1709e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.layers.Input(shape=(None,), dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(None,), dtype='int32')\n",
    "x = model(input, attention_mask=mask)\n",
    "#x = x.last_hidden_state[:, -1]\n",
    "x = tf.reduce_mean(x.last_hidden_state, axis=1)\n",
    "x = tf.keras.layers.Dense(768, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "output = tf.keras.layers.Dense(n_categories, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61f3a1a7-79e2-4887-8102-fced89c05a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tfgpt2_model (TFGPT2Model)     TFBaseModelOutputWi  124247040   ['input_1[0][0]',                \n",
      "                                thPastAndCrossAtten               'input_2[0][0]']                \n",
      "                                tions(last_hidden_s                                               \n",
      "                                tate=(None, None, 7                                               \n",
      "                                68),                                                              \n",
      "                                 past_key_values=((                                               \n",
      "                                2, None, 12, None,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, None                                               \n",
      "                                , 64),                                                            \n",
      "                                 (2, None, 12, None                                               \n",
      "                                , 64),                                                            \n",
      "                                 (2, None, 12, None                                               \n",
      "                                , 64),                                                            \n",
      "                                 (2, None, 12, None                                               \n",
      "                                , 64),                                                            \n",
      "                                 (2, None, 12, None                                               \n",
      "                                , 64),                                                            \n",
      "                                 (2, None, 12, None                                               \n",
      "                                , 64),                                                            \n",
      "                                 (2, None, 12, None                                               \n",
      "                                , 64),                                                            \n",
      "                                 (2, None, 12, None                                               \n",
      "                                , 64),                                                            \n",
      "                                 (2, None, 12, None                                               \n",
      "                                , 64),                                                            \n",
      "                                 (2, None, 12, None                                               \n",
      "                                , 64),                                                            \n",
      "                                 (2, None, 12, None                                               \n",
      "                                , 64)),                                                           \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None,                                                \n",
      "                                cross_attentions=No                                               \n",
      "                                ne)                                                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 768)         0           ['tfgpt2_model[0][0]']           \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 768)          590592      ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 768)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            1538        ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 124,839,170\n",
      "Trainable params: 124,839,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf = tf.keras.Model([input, mask], output)\n",
    "clf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa73f56",
   "metadata": {},
   "source": [
    "Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efea6c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 6\n",
    "batch_size = 6\n",
    "lr = 2e-05 # 1e-5\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0acc3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(\n",
    "    learning_rate=lr, # HF recommendation\n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0\n",
    ")\n",
    "\n",
    "loss = CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c456389",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2aa51984",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcee38da-2ea9-4fa1-80a2-222bc2878038",
   "metadata": {},
   "source": [
    "Last thing we need to do is preparing the target tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ca46e32-7934-4695-ae4f-e429927da2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_in = tf.constant(train_data['Labels'], dtype=tf.int32)\n",
    "y_val_in = tf.constant(val_data['Labels'], dtype=tf.int32)\n",
    "y_test_in = tf.constant(test_data['Labels'], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aceadd7",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3e9bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/6\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"attn\" \"                 f\"(type TFAttention).\n\n{{function_node __wrapped__Split_num_split_3_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[6,512,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Split] name: split\n\nCall arguments received by layer \"attn\" \"                 f\"(type TFAttention):\n  • x=tf.Tensor(shape=(6, 512, 768), dtype=float32)\n  • layer_past=None\n  • attention_mask=tf.Tensor(shape=(6, 1, 1, 512), dtype=float32)\n  • head_mask=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • use_cache=True\n  • output_attentions=False\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39mpatience)\n\u001b[0;32m      5\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints/best_weights\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mX_train_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mX_train_mask\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mX_val_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mX_val_mask\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m milli_sec2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining is completed after\u001b[39m\u001b[38;5;124m\"\u001b[39m, milli_sec2\u001b[38;5;241m-\u001b[39mmilli_sec1)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_tf_utils.py:437\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py:805\u001b[0m, in \u001b[0;36mTFGPT2Model.call\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;129m@unpack_inputs\u001b[39m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(GPT2_INPUTS_DOCSTRING)\n\u001b[0;32m    762\u001b[0m \u001b[38;5;129m@add_code_sample_docstrings\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    782\u001b[0m     training: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    783\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[TFBaseModelOutputWithPastAndCrossAttentions, Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m    784\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;124;03m    encoder_hidden_states  (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;124;03m        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;124;03m        `past`). Set to `False` during training, `True` during generation\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 805\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_tf_utils.py:437\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py:516\u001b[0m, in \u001b[0;36mTFGPT2MainLayer.call\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    514\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (tf\u001b[38;5;241m.\u001b[39mreshape(hidden_states, output_shape),)\n\u001b[1;32m--> 516\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m hidden_states, present \u001b[38;5;241m=\u001b[39m outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py:280\u001b[0m, in \u001b[0;36mTFBlock.call\u001b[1;34m(self, x, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, training)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    269\u001b[0m     x,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    277\u001b[0m     training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    278\u001b[0m ):\n\u001b[0;32m    279\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(x)\n\u001b[1;32m--> 280\u001b[0m     output_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m     a \u001b[38;5;241m=\u001b[39m output_attn[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m output_attn[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py:175\u001b[0m, in \u001b[0;36mTFAttention.call\u001b[1;34m(self, x, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, training)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_attn(x)\n\u001b[1;32m--> 175\u001b[0m     query, key, value \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_heads(query)\n\u001b[0;32m    178\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_heads(key)\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"attn\" \"                 f\"(type TFAttention).\n\n{{function_node __wrapped__Split_num_split_3_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[6,512,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Split] name: split\n\nCall arguments received by layer \"attn\" \"                 f\"(type TFAttention):\n  • x=tf.Tensor(shape=(6, 512, 768), dtype=float32)\n  • layer_past=None\n  • attention_mask=tf.Tensor(shape=(6, 1, 1, 512), dtype=float32)\n  • head_mask=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • use_cache=True\n  • output_attentions=False\n  • training=True"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "milli_sec1 = int(round(time.time() * 1000))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=patience)\n",
    "model_checkpoint = ModelCheckpoint('./checkpoints/best_weights', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "history = clf.fit(\n",
    "    x = {'input_1':X_train_in, 'input_2':X_train_mask},\n",
    "    y = to_categorical(y_train_in),\n",
    "    validation_data = ({'input_1':X_val_in, 'input_2':X_val_mask},\n",
    "                        to_categorical(y_val_in)),\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "milli_sec2 = int(round(time.time() * 1000))\n",
    "print(\"Training is completed after\", milli_sec2-milli_sec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdf3bfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='best')\n",
    "#plt.savefig('train_history.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e02cca3",
   "metadata": {},
   "source": [
    "Load best model from checkpoint during training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e43470c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x21943fc0910>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.load_weights('./checkpoints/best_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4550a3cf-0aa3-4b29-9fbc-dd7090731897",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.training = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac7e299",
   "metadata": {},
   "source": [
    "Classification report on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "396a8b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/12 [===================>..........] - ETA: 1s"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'tfgpt2_for_sequence_classification/transformer/h_._9/attn/Softmax' defined at (most recent call last):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\Temp\\ipykernel_10204\\3519990862.py\", line 1, in <module>\n      print(classification_report(val_data['Labels'], np.argmax(model.predict({'input_ids': X_val['input_ids'], 'attention_mask': X_val['attention_mask']}).logits, axis=1)))\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1050, in run_call_with_unpacked_inputs\n      tf.convert_to_tensor([new_num_tokens, old_embedding_dim]),\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1061, in call\n      transformer_outputs = self.transformer(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1050, in run_call_with_unpacked_inputs\n      tf.convert_to_tensor([new_num_tokens, old_embedding_dim]),\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 460, in call\n      for i, (block, layer_past) in enumerate(zip(self.h, past_key_values)):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 464, in call\n      outputs = block(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 252, in call\n      output_attn = self.attn(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 195, in call\n      attn_outputs = self._attn(query, key, value, attention_mask, head_mask, output_attentions, training=training)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 130, in _attn\n      w = stable_softmax(w, axis=-1)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\tf_utils.py\", line 70, in stable_softmax\n      return tf.nn.softmax(logits=logits + 1e-9, axis=axis, name=name)\nNode: 'tfgpt2_for_sequence_classification/transformer/h_._9/attn/Softmax'\nOOM when allocating tensor with shape[32,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node tfgpt2_for_sequence_classification/transformer/h_._9/attn/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_197317]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(val_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabels\u001b[39m\u001b[38;5;124m'\u001b[39m], np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'tfgpt2_for_sequence_classification/transformer/h_._9/attn/Softmax' defined at (most recent call last):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\Temp\\ipykernel_10204\\3519990862.py\", line 1, in <module>\n      print(classification_report(val_data['Labels'], np.argmax(model.predict({'input_ids': X_val['input_ids'], 'attention_mask': X_val['attention_mask']}).logits, axis=1)))\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1050, in run_call_with_unpacked_inputs\n      tf.convert_to_tensor([new_num_tokens, old_embedding_dim]),\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1061, in call\n      transformer_outputs = self.transformer(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1050, in run_call_with_unpacked_inputs\n      tf.convert_to_tensor([new_num_tokens, old_embedding_dim]),\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 460, in call\n      for i, (block, layer_past) in enumerate(zip(self.h, past_key_values)):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 464, in call\n      outputs = block(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 252, in call\n      output_attn = self.attn(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 195, in call\n      attn_outputs = self._attn(query, key, value, attention_mask, head_mask, output_attentions, training=training)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 130, in _attn\n      w = stable_softmax(w, axis=-1)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\tf_utils.py\", line 70, in stable_softmax\n      return tf.nn.softmax(logits=logits + 1e-9, axis=axis, name=name)\nNode: 'tfgpt2_for_sequence_classification/transformer/h_._9/attn/Softmax'\nOOM when allocating tensor with shape[32,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node tfgpt2_for_sequence_classification/transformer/h_._9/attn/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_197317]"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_data['Labels'], np.argmax(clf.predict({'input_ids': X_val['input_ids'], 'attention_mask': X_val['attention_mask']}).logits, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04f8ebc",
   "metadata": {},
   "source": [
    "Make predictions on the testing set and compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f446efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/419 [===========>..................] - ETA: 3:14"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'tfgpt2_for_sequence_classification_1/GatherV2' defined at (most recent call last):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\Temp\\ipykernel_12628\\3919007435.py\", line 1, in <module>\n      predicted = model.predict({'input_ids': X_test['input_ids'], 'attention_mask': X_test['attention_mask']}, batch_size=1).logits\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1050, in run_call_with_unpacked_inputs\n      tf.convert_to_tensor([new_num_tokens, old_embedding_dim]),\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1080, in call\n      if self.config.pad_token_id is None:\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1083, in call\n      if input_ids is not None:\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1095, in call\n      in_logits = tf.gather(logits, sequence_lengths, batch_dims=1, axis=1)\nNode: 'tfgpt2_for_sequence_classification_1/GatherV2'\nDetected at node 'tfgpt2_for_sequence_classification_1/GatherV2' defined at (most recent call last):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\Temp\\ipykernel_12628\\3919007435.py\", line 1, in <module>\n      predicted = model.predict({'input_ids': X_test['input_ids'], 'attention_mask': X_test['attention_mask']}, batch_size=1).logits\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1050, in run_call_with_unpacked_inputs\n      tf.convert_to_tensor([new_num_tokens, old_embedding_dim]),\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1080, in call\n      if self.config.pad_token_id is None:\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1083, in call\n      if input_ids is not None:\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1095, in call\n      in_logits = tf.gather(logits, sequence_lengths, batch_dims=1, axis=1)\nNode: 'tfgpt2_for_sequence_classification_1/GatherV2'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  indices[0] = -1 is not in [0, 512)\n\t [[{{node tfgpt2_for_sequence_classification_1/GatherV2}}]]\n\t [[tfgpt2_for_sequence_classification_1/GatherV2/_305]]\n  (1) INVALID_ARGUMENT:  indices[0] = -1 is not in [0, 512)\n\t [[{{node tfgpt2_for_sequence_classification_1/GatherV2}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_106146]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/cpu:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m      3\u001b[0m     y_predicted \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predicted, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m     targets \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'tfgpt2_for_sequence_classification_1/GatherV2' defined at (most recent call last):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\Temp\\ipykernel_12628\\3919007435.py\", line 1, in <module>\n      predicted = model.predict({'input_ids': X_test['input_ids'], 'attention_mask': X_test['attention_mask']}, batch_size=1).logits\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1050, in run_call_with_unpacked_inputs\n      tf.convert_to_tensor([new_num_tokens, old_embedding_dim]),\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1080, in call\n      if self.config.pad_token_id is None:\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1083, in call\n      if input_ids is not None:\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1095, in call\n      in_logits = tf.gather(logits, sequence_lengths, batch_dims=1, axis=1)\nNode: 'tfgpt2_for_sequence_classification_1/GatherV2'\nDetected at node 'tfgpt2_for_sequence_classification_1/GatherV2' defined at (most recent call last):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\Temp\\ipykernel_12628\\3919007435.py\", line 1, in <module>\n      predicted = model.predict({'input_ids': X_test['input_ids'], 'attention_mask': X_test['attention_mask']}, batch_size=1).logits\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1050, in run_call_with_unpacked_inputs\n      tf.convert_to_tensor([new_num_tokens, old_embedding_dim]),\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1080, in call\n      if self.config.pad_token_id is None:\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1083, in call\n      if input_ids is not None:\n    File \"C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 1095, in call\n      in_logits = tf.gather(logits, sequence_lengths, batch_dims=1, axis=1)\nNode: 'tfgpt2_for_sequence_classification_1/GatherV2'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  indices[0] = -1 is not in [0, 512)\n\t [[{{node tfgpt2_for_sequence_classification_1/GatherV2}}]]\n\t [[tfgpt2_for_sequence_classification_1/GatherV2/_305]]\n  (1) INVALID_ARGUMENT:  indices[0] = -1 is not in [0, 512)\n\t [[{{node tfgpt2_for_sequence_classification_1/GatherV2}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_106146]"
     ]
    }
   ],
   "source": [
    "predicted = model.predict({'input_ids': X_test['input_ids'], 'attention_mask': X_test['attention_mask']}).logits\n",
    "y_predicted = np.argmax(predicted, axis=1)\n",
    "\n",
    "targets = test_data['Labels']\n",
    "print(classification_report(targets, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9469c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(targets, y_predicted)\n",
    "precision=precision_score(targets, y_predicted)\n",
    "recall=recall_score(targets, y_predicted)\n",
    "roc_auc=roc_auc_score(targets, y_predicted)\n",
    "f1=f1_score(targets, y_predicted)\n",
    "f2 = (5*precision*recall) / (4*precision+recall)\n",
    "\n",
    "conf_matrix = confusion_matrix(targets, y_predicted)\n",
    "sn.heatmap(conf_matrix, annot=True)\n",
    "\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "acc = ((tp+tn)/(tp+tn+fp+fn))\n",
    "print(\"TP=\",tp)\n",
    "print(\"TN=\",tn)\n",
    "print(\"FP=\",fp)\n",
    "print(\"FN=\",fn)\n",
    "\n",
    "print(\"Accuracy:%.2f%%\"%(accuracy*100))\n",
    "print(\"Precision:%.2f%%\"%(precision*100))\n",
    "print(\"Recall:%.2f%%\"%(recall*100))\n",
    "print(\"Roc_Auc score:%.2f%%\"%(roc_auc*100))\n",
    "print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "print(\"F2 score:%.2f%%\"%(f2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8942a2b-1d6c-411f-b6c4-9bfeacc992a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
